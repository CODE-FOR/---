{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba28db67-d77c-49ed-96cd-1f2177e7ac04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.nn import Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a701cbf-1b94-4c76-ad2b-20e0c7b59062",
   "metadata": {},
   "source": [
    "## 超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3471a3dc-1667-4ac5-9181-3c7ca19e2449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fb38c636b10>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "cloud_num = 28\n",
    "focal_loss_gmma = 2.0\n",
    "epochs = 150\n",
    "model_name = 'resnet-50'\n",
    "optimizer_name = 'radam'\n",
    "scheduler_name = 'cosine_annealing_warm_restarts'\n",
    "# scheduler_name = 'cosine_annealing'\n",
    "# scheduler_name = 'none'\n",
    "T_0 = 15\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d22b4d-38c9-47e8-b8d1-b4458f67b0b4",
   "metadata": {},
   "source": [
    "## 模型加载\n",
    "\n",
    "使用`torchvision.models`中的resnet50作为预训练模型，并修改其全连接层。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e02ba30-e02e-472b-bfca-97e173ac22d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(cloud_class_nums):\n",
    "    pretrained_model = models.resnet50(weights=models.resnet.ResNet50_Weights.DEFAULT)\n",
    "    num_ftrs = pretrained_model.fc.in_features\n",
    "    pretrained_model.fc = Linear(num_ftrs, cloud_class_nums)\n",
    "    return pretrained_model\n",
    "\n",
    "model = load_model(cloud_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08a5517-a516-47b8-aaff-0027fdf8bde3",
   "metadata": {},
   "source": [
    "## 构建数据集类\n",
    "根据`torch`官方文档修正`transform`参数:\n",
    "- 训练阶段:将图片随机切分并`resize`到$224 \\times 224$\n",
    "- 验证阶段:\n",
    "  - 将图片`resize`到$256 \\times 256$\n",
    "  - 截取`center`的$24 \\times 224$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf3de80b-39c3-4987-877d-948ab880d1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "class CloudImageDataSet(Dataset):\n",
    "    def __init__(self, img_dir_path, img_set_with_label: dict, data_transforms=None, dataset = ''):\n",
    "        self.imgs = list(img_set_with_label.keys())\n",
    "        self.labels = list(img_set_with_label.values())\n",
    "        self.data_transforms = data_transforms\n",
    "        self.img_dir_path = img_dir_path\n",
    "        self.dataset = dataset\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "    \n",
    "    def __getitem__(self, k):\n",
    "        img_name = self.imgs[k]\n",
    "        label = torch.nn.functional.one_hot(torch.tensor(self.labels[k] - 1), num_classes=cloud_num).double()\n",
    "        img_path = os.path.join(self.img_dir_path, img_name)\n",
    "        with open(img_path, 'rb') as img_file:\n",
    "            img = Image.open(img_file)\n",
    "            img = img.convert('RGB')\n",
    "        img_file.close()\n",
    "        return self.data_transforms[self.dataset](img), label\n",
    "\n",
    "    \n",
    "data_transforms = {\n",
    "    'Train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'Test': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c21778da-5579-4cd7-8b78-1e7059dda83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89093d77-8440-4cf6-8094-8cb081498f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas\n",
    "\n",
    "train_dataset_df = pandas.read_csv('./cloud_dataset/train.csv').T\n",
    "train_image_name_and_label_set = {}\n",
    "for k, v in train_dataset_df.to_dict().items():\n",
    "    train_image_name_and_label_set[v['FileName']] = v['Code']\n",
    "val_dataset_df = pandas.read_csv('./cloud_dataset/standard_answer.csv').T\n",
    "val_image_name_and_label_set = {}\n",
    "for k, v in val_dataset_df.to_dict().items():\n",
    "    val_image_name_and_label_set[v['FileName']] = v['Code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf46454d-87ea-4a41-a279-56e6e9f2510f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866d355c-2626-4b79-90b0-c249d1b7253f",
   "metadata": {},
   "source": [
    "## Focal Loss\n",
    "\n",
    "$-(1-p_t)log(p_t)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1da06b-3421-4ce4-9fd1-e9ab2da3a917",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Softmax, CrossEntropyLoss\n",
    "\n",
    "class FocalLoss(torch.nn.Module):\n",
    "    def __init__(self, gmma):\n",
    "        super().__init__()\n",
    "        self.gmma = gmma\n",
    "        self.softmax = Softmax(dim=1)\n",
    "        self.cross_entropy_loss = CrossEntropyLoss()\n",
    "    \n",
    "    def forward(self, pred, label):\n",
    "        pred_after_softmax = self.softmax(pred)\n",
    "        ce = - torch.log(pred_after_softmax) * label\n",
    "        focal_loss = (((1 - pred_after_softmax * label) ** self.gmma) * ce).sum() / batch_size\n",
    "        return focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab05630-751a-400e-a552-f76da18a18c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_fn = torch.nn.CrossEntropyLoss()\n",
    "loss_fn = FocalLoss(gmma=focal_loss_gmma)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = torch.optim.RAdam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=T_0, T_mult=1, verbose=True)\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=T_0, verbose=True, eta_min=1e-4)\n",
    "train_dataset = CloudImageDataSet('./cloud_dataset/images/', train_image_name_and_label_set, data_transforms, 'Train')\n",
    "val_dataset = CloudImageDataSet('./cloud_dataset/images', val_image_name_and_label_set, data_transforms, 'Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953cf192-95ff-446b-acaf-e42e5a406f42",
   "metadata": {},
   "source": [
    "## 训练\n",
    "将`test.csv`中的数据加载，进行`K-Fold`训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712950f1-82ec-435f-ba3c-f90134cab275",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import f1_score\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import time\n",
    "\n",
    "max_f1_score = 0\n",
    "max_f1_score_model_name = ''\n",
    "model_f1_set = []\n",
    "model_avg_loss_set = []\n",
    "iteration = 0\n",
    "train_loss_set = []\n",
    "timestamp = time.time()\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, sharey=True)\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    train_set, val_set = train_dataset, val_dataset\n",
    "    train_dataloader =  DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "    val_dataloader = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=8)\n",
    "    size = len(train_dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 20 == 0:\n",
    "            iteration += 1\n",
    "            loss, current = loss.item(), batch * batch_size\n",
    "            train_loss_set.append(loss)\n",
    "            ax1.clear()\n",
    "            ax1.set_title('Train Loss')\n",
    "            ax1.plot([20 * _ for _ in range(iteration)], train_loss_set, label=\"loss\")\n",
    "            display.clear_output(wait=True)\n",
    "            display.display(f)\n",
    "    test_loss, correct = 0, 0\n",
    "    size = len(val_dataloader.dataset)\n",
    "    num_batches = len(val_dataloader)\n",
    "    if epoch < 14:\n",
    "        scheduler.step()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred_set = torch.tensor([])\n",
    "        y_set = torch.tensor([])\n",
    "        for X, y in val_dataloader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            pred_set = torch.cat((pred_set, pred.cpu()), 0)\n",
    "            y_set = torch.cat((y_set, y.cpu()), 0)\n",
    "            correct += (pred.argmax(1) == y.argmax(1)).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    f1 = f1_score(pred_set.argmax(1), y_set.argmax(1), average=None).sum().item() / cloud_num\n",
    "    if f1 > max_f1_score:\n",
    "        max_f1_score = f1\n",
    "        max_f1_score_model_name = f'./model_state_dict/model-{batch_size}-{focal_loss_gmma}-{model_name}-epoch{epoch}-optimizer{optimizer_name}-scheduler{scheduler_name}-f1-score{f1}'\n",
    "    torch.save(model.state_dict(), f'./model_state_dict/model-{batch_size}-{focal_loss_gmma}-{model_name}-epoch{epoch}-optimizer{optimizer_name}-scheduler{scheduler_name}-f1-score{f1}')\n",
    "    log_file = open(f'./log/log-{batch_size}-{focal_loss_gmma}-{model_name}-optimizer{optimizer_name}-scheduler{scheduler_name}-time{timestamp}.txt', 'a')\n",
    "    print(f'epoch {epoch}---------------------------', file=log_file)\n",
    "    model_f1_set.append(f1)\n",
    "    model_avg_loss_set.append(test_loss)\n",
    "    ax2.clear()\n",
    "    ax2.plot(range(epoch + 1), model_f1_set, label=\"f1 score\")\n",
    "    ax2.plot(range(epoch + 1), model_avg_loss_set, label=\"avg loss\")\n",
    "    ax2.legend()\n",
    "    ax2.set_title('Test Loss&F1')\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(f)\n",
    "    print(f\"Val: \\n Accuracy: {(100*correct):>0.1f}%, f1_score: {f1:>8f} Avg loss: {test_loss:>8f} \\n\", file=log_file)\n",
    "    log_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadbbebf-8af9-4714-843f-af861e473b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_df = pandas.read_csv('/home/codefor/cloud-form/cloud_dataset/test.csv').T\n",
    "test_image_name_set = []\n",
    "for k, v in test_dataset_df.to_dict().items():\n",
    "    test_image_name_set.append(v['FileName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32752898-0742-4af8-89e8-88271a9eb34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CloudImageDataSetForTest(Dataset):\n",
    "    def __init__(self, img_dir_path, img_set: list, data_transforms=None, dataset = ''):\n",
    "        self.imgs = img_set\n",
    "        self.data_transforms = data_transforms\n",
    "        self.img_dir_path = img_dir_path\n",
    "        self.dataset = dataset\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "    \n",
    "    def __getitem__(self, k):\n",
    "        img_name = self.imgs[k]\n",
    "        img_path = os.path.join(self.img_dir_path, img_name)\n",
    "        with open(img_path, 'rb') as img_file:\n",
    "            img = Image.open(img_file)\n",
    "            img = img.convert('RGB')\n",
    "        img_file.close()\n",
    "        return self.data_transforms[self.dataset](img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9438d2f-f6aa-4c53-87d3-205555f78997",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CloudImageDataSetForTest('./cloud_dataset/images/', test_image_name_set, data_transforms, 'Test')\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9eae17-0208-4a8b-8446-97470c7a9c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('./model_state_dict/model-64-2.0-resnet-50-epoch24-optimizerradam-schedulercosine_annealing_warm_restarts-f1-score0.39702159977146195'))\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    pred_set = torch.tensor([])\n",
    "    for X in test_dataloader:\n",
    "        X = X.to(device)\n",
    "        pred = model(X)\n",
    "        pred_set = torch.cat((pred_set, pred.cpu().argmax(1) + 1), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ad7fe0-bce9-4176-91c2-cd99bed3648b",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = zip(test_image_name_set, pred_set.int().tolist())\n",
    "submission = dict(submission)\n",
    "submission = pandas.DataFrame([submission]).T\n",
    "submission.to_csv('./cloud_dataset/submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1e7e47-d7fa-4b2b-a7b3-2fda6475707e",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_f1_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
