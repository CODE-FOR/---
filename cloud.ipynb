{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba28db67-d77c-49ed-96cd-1f2177e7ac04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.nn import Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a701cbf-1b94-4c76-ad2b-20e0c7b59062",
   "metadata": {},
   "source": [
    "## 超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3471a3dc-1667-4ac5-9181-3c7ca19e2449",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "k_fold = 10\n",
    "cloud_num = 28\n",
    "focal_loss_gmma = 2.0\n",
    "epochs = 100\n",
    "model_name = 'resnet-50'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d22b4d-38c9-47e8-b8d1-b4458f67b0b4",
   "metadata": {},
   "source": [
    "## 模型加载\n",
    "\n",
    "使用`torchvision.models`中的resnet50作为预训练模型，并修改其全连接层。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e02ba30-e02e-472b-bfca-97e173ac22d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(cloud_class_nums):\n",
    "    pretrained_model = models.resnet50(weights=models.resnet.ResNet50_Weights.DEFAULT)\n",
    "    num_ftrs = pretrained_model.fc.in_features\n",
    "    pretrained_model.fc = Linear(num_ftrs, cloud_class_nums)\n",
    "    return pretrained_model\n",
    "\n",
    "model = load_model(cloud_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08a5517-a516-47b8-aaff-0027fdf8bde3",
   "metadata": {},
   "source": [
    "## 构建数据集类\n",
    "根据`torch`官方文档修正`transform`参数:\n",
    "- 训练阶段:将图片随机切分并`resize`到$224 \\times 224$\n",
    "- 验证阶段:\n",
    "  - 将图片`resize`到$256 \\times 256$\n",
    "  - 截取`center`的$24 \\times 224$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf3de80b-39c3-4987-877d-948ab880d1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "class CloudImageDataSet(Dataset):\n",
    "    def __init__(self, img_dir_path, img_set_with_label: dict, data_transforms=None, dataset = ''):\n",
    "        self.imgs = list(img_set_with_label.keys())\n",
    "        self.labels = list(img_set_with_label.values())\n",
    "        self.data_transforms = data_transforms\n",
    "        self.img_dir_path = img_dir_path\n",
    "        self.dataset = dataset\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "    \n",
    "    def __getitem__(self, k):\n",
    "        img_name = self.imgs[k]\n",
    "        label = torch.nn.functional.one_hot(torch.tensor(self.labels[k] - 1), num_classes=cloud_num).double()\n",
    "        img_path = os.path.join(self.img_dir_path, img_name)\n",
    "        with open(img_path, 'rb') as img_file:\n",
    "            img = Image.open(img_file)\n",
    "            img = img.convert('RGB')\n",
    "        img_file.close()\n",
    "        return self.data_transforms[self.dataset](img), label\n",
    "\n",
    "    \n",
    "data_transforms = {\n",
    "    'Train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'Test': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c21778da-5579-4cd7-8b78-1e7059dda83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89093d77-8440-4cf6-8094-8cb081498f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas\n",
    "\n",
    "train_dataset_df = pandas.read_csv('/home/codefor/work/cloud_dataset/train.csv').T\n",
    "train_image_name_and_label_set = {}\n",
    "for k, v in train_dataset_df.to_dict().items():\n",
    "    train_image_name_and_label_set[v['FileName']] = v['Code']\n",
    "val_dataset_df = pandas.read_csv('/home/codefor/work/cloud_dataset/standard_answer.csv').T\n",
    "val_image_name_and_label_set = {}\n",
    "for k, v in val_dataset_df.to_dict().items():\n",
    "    val_image_name_and_label_set[v['FileName']] = v['Code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf46454d-87ea-4a41-a279-56e6e9f2510f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866d355c-2626-4b79-90b0-c249d1b7253f",
   "metadata": {},
   "source": [
    "## Focal Loss\n",
    "\n",
    "$-(1-p_t)log(p_t)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b1da06b-3421-4ce4-9fd1-e9ab2da3a917",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Softmax, CrossEntropyLoss\n",
    "\n",
    "class FocalLoss(torch.nn.Module):\n",
    "    def __init__(self, gmma):\n",
    "        super().__init__()\n",
    "        self.gmma = gmma\n",
    "        self.softmax = Softmax(dim=1)\n",
    "        self.cross_entropy_loss = CrossEntropyLoss()\n",
    "    \n",
    "    def forward(self, pred, label):\n",
    "        pred_after_softmax = self.softmax(pred)\n",
    "        ce = - torch.log(pred_after_softmax) * label\n",
    "        focal_loss = (((1 - pred_after_softmax * label) ** self.gmma) * ce).sum() / batch_size\n",
    "        return focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fab05630-751a-400e-a552-f76da18a18c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_fn = torch.nn.CrossEntropyLoss()\n",
    "loss_fn = FocalLoss(gmma=focal_loss_gmma)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "train_dataset = CloudImageDataSet('/home/codefor/work/cloud_dataset/images/', train_image_name_and_label_set, data_transforms, 'Train')\n",
    "val_dataset = CloudImageDataSet('/home/codefor/work/cloud_dataset/images', val_image_name_and_label_set, data_transforms, 'Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953cf192-95ff-446b-acaf-e42e5a406f42",
   "metadata": {},
   "source": [
    "## 训练\n",
    "将`test.csv`中的数据加载，进行`K-Fold`训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712950f1-82ec-435f-ba3c-f90134cab275",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import f1_score\n",
    "import time\n",
    "\n",
    "# def k_fold_split(dataset, epoch, total_size, seg):\n",
    "#     trll = 0\n",
    "#     trlr = epoch * seg\n",
    "#     vall = trlr\n",
    "#     valr = epoch * seg + seg\n",
    "#     trrl = valr\n",
    "#     trrr = total_size\n",
    "#     train_left_indices = list(range(trll,trlr))\n",
    "#     train_right_indices = list(range(trrl,trrr))       \n",
    "#     train_indices = train_left_indices + train_right_indices\n",
    "#     val_indices = list(range(vall,valr))\n",
    "#     train_set = torch.utils.data.dataset.Subset(dataset, train_indices)\n",
    "#     val_set = torch.utils.data.dataset.Subset(dataset, val_indices)\n",
    "#     return train_set, val_set\n",
    "\n",
    "\n",
    "# total_size = len(dataset)\n",
    "# fraction = 1 / k_fold\n",
    "# seg = int(total_size * fraction)\n",
    "max_f1_score = 0\n",
    "max_f1_score_model_name = ''\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # train_set, val_set = k_fold_split(dataset, epoch % k_fold, total_size, seg)\n",
    "    train_set, val_set = train_dataset, val_dataset\n",
    "    train_dataloader =  DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "    val_dataloader = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=8)\n",
    "    size = len(train_dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 20 == 0:\n",
    "            loss, current = loss.item(), batch * batch_size\n",
    "    test_loss, correct = 0, 0\n",
    "    size = len(val_dataloader.dataset)\n",
    "    num_batches = len(val_dataloader)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred_set = torch.tensor([])\n",
    "        y_set = torch.tensor([])\n",
    "        for X, y in val_dataloader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            pred_set = torch.cat((pred_set, pred.cpu()), 0)\n",
    "            y_set = torch.cat((y_set, y.cpu()), 0)\n",
    "            correct += (pred.argmax(1) == y.argmax(1)).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    f1 = f1_score(pred_set.argmax(1), y_set.argmax(1), average=None).sum().item() / cloud_num\n",
    "    if f1 > max_f1_score:\n",
    "        max_f1_score = f1\n",
    "        max_f1_score_model_name = f'./model_state_dict/model-{batch_size}-{focal_loss_gmma}-{model_name}-epoch{epoch}-f1-score{f1}'\n",
    "    torch.save(model.state_dict(), f'./model_state_dict/model-{batch_size}-{focal_loss_gmma}-{model_name}-epoch{epoch}-f1-score{f1}')\n",
    "    log_file = open(f'./log/log-{batch_size}-{focal_loss_gmma}-{model_name}.txt', 'a')\n",
    "    print(f'epoch {epoch}---------------------------', file=log_file)\n",
    "    print(f\"Val: \\n Accuracy: {(100*correct):>0.1f}%, f1_score: {f1:>8f} Avg loss: {test_loss:>8f} \\n\", file=log_file)\n",
    "    log_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fadbbebf-8af9-4714-843f-af861e473b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_df = pandas.read_csv('/home/codefor/work/cloud_dataset/test.csv').T\n",
    "test_image_name_set = []\n",
    "for k, v in test_dataset_df.to_dict().items():\n",
    "    test_image_name_set.append(v['FileName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32752898-0742-4af8-89e8-88271a9eb34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CloudImageDataSetForTest(Dataset):\n",
    "    def __init__(self, img_dir_path, img_set: list, data_transforms=None, dataset = ''):\n",
    "        self.imgs = img_set\n",
    "        self.data_transforms = data_transforms\n",
    "        self.img_dir_path = img_dir_path\n",
    "        self.dataset = dataset\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "    \n",
    "    def __getitem__(self, k):\n",
    "        img_name = self.imgs[k]\n",
    "        img_path = os.path.join(self.img_dir_path, img_name)\n",
    "        with open(img_path, 'rb') as img_file:\n",
    "            img = Image.open(img_file)\n",
    "            img = img.convert('RGB')\n",
    "        img_file.close()\n",
    "        return self.data_transforms[self.dataset](img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b9438d2f-f6aa-4c53-87d3-205555f78997",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CloudImageDataSetForTest('/home/codefor/work/cloud_dataset/images/', test_image_name_set, data_transforms, 'Test')\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a9eae17-0208-4a8b-8446-97470c7a9c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(max_f1_score_model_name))\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    pred_set = torch.tensor([])\n",
    "    for X in test_dataloader:\n",
    "        X = X.to(device)\n",
    "        pred = model(X)\n",
    "        pred_set = torch.cat((pred_set, pred.cpu().argmax(1) + 1), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2ad7fe0-bce9-4176-91c2-cd99bed3648b",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = zip(test_image_name_set, pred_set.int().tolist())\n",
    "submission = dict(submission)\n",
    "submission = pandas.DataFrame([submission]).T\n",
    "submission.to_csv('./cloud_dataset/submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0c6b5150-8554-4fa3-a482-8de53cecef7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.374368257841779"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c263afc-bcba-4acf-9228-fd3e398f3847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 52.1%, f1_score: 0.374368 Avg loss: 0.997961 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_loss, correct = 0, 0\n",
    "size = len(val_dataloader.dataset)\n",
    "num_batches = len(val_dataloader)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    pred_set = torch.tensor([])\n",
    "    y_set = torch.tensor([])\n",
    "    for X, y in val_dataloader:\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        pred = model(X)\n",
    "        test_loss += loss_fn(pred, y).item()\n",
    "        pred_set = torch.cat((pred_set, pred.cpu()), 0)\n",
    "        y_set = torch.cat((y_set, y.cpu()), 0)\n",
    "        correct += (pred.argmax(1) == y.argmax(1)).type(torch.float).sum().item()\n",
    "test_loss /= num_batches\n",
    "correct /= size\n",
    "f1 = f1_score(pred_set.argmax(1), y_set.argmax(1), average=None).sum().item() / cloud_num\n",
    "torch.save(model.state_dict(), f'./model_state_dict/{model_name}-epoch{epoch + 51}-f1{f1}')\n",
    "print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, f1_score: {f1:>8f} Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdb4d2d-744b-4f83-8808-34ecac45ca38",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(max_f1_score_model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99948361-b525-4525-abc3-bd24f8a92680",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
